{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from numpy import reshape\n",
    "from sklearn import metrics\n",
    "from collections import Counter \n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_dec10_task4_missing_supplement.csv')\n",
    "# data = pd.read_csv('train_dec08_task4_missing.csv')\n",
    "# data = pd.read_csv('merge.csv')\n",
    "pred_data = pd.read_csv('test_dec08_task4_missing_only_features.csv')\n",
    "\n",
    "\n",
    "data = data.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features and labels\n",
    "X_train = train_data.iloc[:, :14]\n",
    "y_train = train_data.iloc[:, 14]\n",
    "\n",
    "X_test = test_data.iloc[:, :14]\n",
    "y_test = test_data.iloc[:, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gaman\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:700: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaman\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:700: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gaman\\anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:700: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "imp_mean = IterativeImputer(random_state=0, estimator=ExtraTreesRegressor(n_estimators=10, random_state=0))\n",
    "\n",
    "\n",
    "X_train = imp_mean.fit_transform(X_train)\n",
    "X_test = imp_mean.fit_transform(X_test)\n",
    "pred_data = imp_mean.fit_transform(pred_data)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "pred_data = pd.DataFrame(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform the labels to numbers to fit XGBoost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1606, 3: 778, 2: 2030, 0: 786})"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the imbalance of the data\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use SMOTE to balance the data\n",
    "# # deprecated: SMOTE + TomekLinks is not better than SMOTE\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# X_train, y_train = SMOTE(random_state=42).fit_resample(X_train, y_train)\n",
    "\n",
    "# # check the imbalance of the data again\n",
    "# print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "# print(f\"Testing target statistics: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif\n",
    "# from sklearn.feature_selection import f_classif\n",
    "# from sklearn.feature_selection import chi2\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "# # choose the best k features numbers\n",
    "# select_k = 10\n",
    "\n",
    "# selection = SelectKBest(mutual_info_classif, k=select_k).fit(X_train, y_train)\n",
    "\n",
    "# # show the selected features\n",
    "# ''' Higher score means more important with the target \n",
    "#     Lower score means less important with the target\n",
    "# '''\n",
    "\n",
    "# features = X_train.columns[selection.get_support()]\n",
    "# print(f\"features: {features}\")\n",
    "# print(f\"scores: {selection.scores_}\")\n",
    "# X_train = selection.fit_transform(X_train, y_train)\n",
    "# X_test = selection.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-41 {color: black;background-color: white;}#sk-container-id-41 pre{padding: 0;}#sk-container-id-41 div.sk-toggleable {background-color: white;}#sk-container-id-41 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-41 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-41 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-41 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-41 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-41 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-41 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-41 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-41 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-41 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-41 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-41 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-41 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-41 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-41 div.sk-item {position: relative;z-index: 1;}#sk-container-id-41 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-41 div.sk-item::before, #sk-container-id-41 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-41 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-41 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-41 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-41 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-41 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-41 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-41 div.sk-label-container {text-align: center;}#sk-container-id-41 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-41 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-41\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.36, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" checked><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.36, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.36, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=6, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto', ...)"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build XGBClassifier model\n",
    "xgboostModel = XGBClassifier(n_estimators=100, learning_rate= 0.36)\n",
    "\n",
    "# train data with train_data\n",
    "# xgboostModel.fit(X_train, y_train)\n",
    "xgboostModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集:  0.9946153846153846\n",
      "測試集:  0.4576923076923077\n"
     ]
    }
   ],
   "source": [
    "# print the accuracy\n",
    "print('訓練集: ',xgboostModel.score(X_train,y_train))\n",
    "print('測試集: ',xgboostModel.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the real given data\n",
    "# pred_data = selection.transform(pred_data)\n",
    "answer = xgboostModel.predict(pred_data)\n",
    "answer = le.inverse_transform(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = {\"Id\": [x for x in range(1, len(answer)+1)], \"Category\": answer}\n",
    "df = pd.DataFrame (da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfec9ce077408dc39abd08d3e533064f58e310f5c55395ca594f12859fd117f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
